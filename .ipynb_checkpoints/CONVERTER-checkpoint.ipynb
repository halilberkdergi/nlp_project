{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "novel-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pysummarization.nlpbase.auto_abstractor import AutoAbstractor\n",
    "from pysummarization.tokenizabledoc.simple_tokenizer import SimpleTokenizer\n",
    "from pysummarization.abstractabledoc.top_n_rank_abstractor import TopNRankAbstractor\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "administrative-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(subtitle_file,excel_name,sheet_name):\n",
    "    \n",
    "    #read input file\n",
    "    file = open(subtitle_file)\n",
    "    SENTENCES_COUNT =0         \n",
    "    data = file.read()\n",
    "\n",
    "    CoList = data.split('\\n')\n",
    "\n",
    "    for i in CoList:\n",
    "        if i:        \n",
    "            SENTENCES_COUNT += 1\n",
    "\n",
    "    data = data.replace('\\n', ' . ')\n",
    "    #close the input file\n",
    "    file.close()\n",
    "\n",
    "    ############\n",
    "    #open the input file in write mode\n",
    "    fin = open(subtitle_file, \"wt\")\n",
    "    #overrite the input file with the resulting data\n",
    "    fin.write(data)\n",
    "    #close the file\n",
    "    fin.close()\n",
    "\n",
    "    ###### read again####\n",
    "    document = open(subtitle_file).read()\n",
    "\n",
    "    ####PANDAS####\n",
    "    df = pd.read_excel(excel_name,header=0,sheet_name=sheet_name,index_col=0)\n",
    "    df.index.name = None\n",
    "    df =df.fillna(0)\n",
    "    df= df.astype(int)\n",
    "    \n",
    "\n",
    "    #####PYSUMMM#####\n",
    "    \n",
    "    auto_abstractor = AutoAbstractor() # Object of automatic summarization.\n",
    "    auto_abstractor.tokenizable_doc = SimpleTokenizer() # Set tokenizer.\n",
    "    auto_abstractor.delimiter_list = [\".\"] # Set delimiter for making a list of sentence.\n",
    "    abstractable_doc = TopNRankAbstractor()# Object of abstracting and filtering document.\n",
    "    \n",
    "    for n in range(1,SENTENCES_COUNT+1):\n",
    "        abstractable_doc.set_top_n(n) # set n = 120 value\n",
    "        result_dict = auto_abstractor.summarize(document, abstractable_doc) # Summarize document.\n",
    "        #print(n )\n",
    "\n",
    "        for i in range(n):\n",
    "            a=result_dict[\"scoring_data\"][i][0]+1\n",
    "            #print('a ='+str(a))\n",
    "            if df['pysum'][a]==0:\n",
    "                df['pysum'][a] = n\n",
    "\n",
    "    #####SUMY#########\n",
    "    LANGUAGE = \"english\"\n",
    "    parser = PlaintextParser.from_file(subtitle_file, Tokenizer(LANGUAGE))\n",
    "    summarizer_lex = LexRankSummarizer()\n",
    "\n",
    "    summarizer_luhn = LuhnSummarizer()\n",
    "\n",
    "    summarizer_lsa = LsaSummarizer()\n",
    "\n",
    "    summarizer_textrank = TextRankSummarizer()\n",
    "\n",
    "    for n in range(1,SENTENCES_COUNT):\n",
    "        summary_lex = summarizer_lex(parser.document,n)\n",
    "        summary_luhn = summarizer_luhn(parser.document,n)\n",
    "        summary_lsa = summarizer_lsa(parser.document,n)\n",
    "        summary_textrank = summarizer_textrank(parser.document,n)\n",
    "        for sentence in summary_lex:        \n",
    "            a=parser.document.sentences.index(sentence)+1\n",
    "            #print('a ='+str(a))\n",
    "            if df['lexrank'][a]==0:\n",
    "                df['lexrank'][a] = n\n",
    "        for sentence in summary_luhn:        \n",
    "            a=parser.document.sentences.index(sentence)+1\n",
    "            #print('a ='+str(a))\n",
    "            if df['luhn'][a]==0:\n",
    "                df['luhn'][a] = n\n",
    "        for sentence in summary_lsa:        \n",
    "            a=parser.document.sentences.index(sentence)+1\n",
    "            #print('a ='+str(a))\n",
    "            if df['lsa'][a]==0:\n",
    "                df['lsa'][a] = n\n",
    "        for sentence in summary_textrank:        \n",
    "            a=parser.document.sentences.index(sentence)+1\n",
    "            #print('a ='+str(a))\n",
    "            if df['textrank'][a]==0:\n",
    "                df['textrank'][a] = n\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surface-puzzle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pysum</th>\n",
       "      <th>lexrank</th>\n",
       "      <th>luhn</th>\n",
       "      <th>lsa</th>\n",
       "      <th>textrank</th>\n",
       "      <th>x1.</th>\n",
       "      <th>x1.3</th>\n",
       "      <th>x1.6</th>\n",
       "      <th>x1.9</th>\n",
       "      <th>x2.2</th>\n",
       "      <th>x2.5</th>\n",
       "      <th>nadir_kelime</th>\n",
       "      <th>konu_ile_alakalı</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>63</td>\n",
       "      <td>109</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>102</td>\n",
       "      <td>24</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>83</td>\n",
       "      <td>27</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>97</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>49</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>66</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>106</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pysum  lexrank  luhn  lsa  textrank  x1.  x1.3  x1.6  x1.9  x2.2  x2.5  \\\n",
       "1        8       78    63  109        88    1     1     1     1     1     1   \n",
       "2       11       64   102   24        83    1     1     1     1     1     1   \n",
       "3       10       71    83   27       106    1     1     1     1     1     0   \n",
       "4        7      110     7   18        12    1     1     1     1     1     1   \n",
       "5        6        2     3   17         4    1     1     1     1     1     0   \n",
       "..     ...      ...   ...  ...       ...  ...   ...   ...   ...   ...   ...   \n",
       "116     99       84    97  115         0    1     1     1     1     1     1   \n",
       "117     49       25    21   20        43    1     1     1     1     1     1   \n",
       "118     39       31    32   16        16    1     1     1     1     1     0   \n",
       "119     24       38    33    1         1    1     1     1     1     1     0   \n",
       "120     66       80    73  106        66    0     0     0     0     0     0   \n",
       "\n",
       "     nadir_kelime  konu_ile_alakalı  \n",
       "1               0                 0  \n",
       "2               0                 0  \n",
       "3               0                 0  \n",
       "4               0                 0  \n",
       "5               0                 0  \n",
       "..            ...               ...  \n",
       "116             0                 0  \n",
       "117             0                 0  \n",
       "118             0                 0  \n",
       "119             0                 0  \n",
       "120             0                 0  \n",
       "\n",
       "[120 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank(subtitle_file='Sub_1.txt',excel_name='data.xlsx',sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "emerging-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "right-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentA = open('Sub_1.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "removed-asthma",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documentA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-84b22cabdbe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbagOfWordsA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocumentA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'documentA' is not defined"
     ]
    }
   ],
   "source": [
    "bagOfWordsA = documentA.split(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "practical-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = set(bagOfWordsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "committed-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsA:\n",
    "    numOfWordsA[word] += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "located-marathon",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-52653aa12ced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "stopwords. words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wicked-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bizarre-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfA = computeTF(numOfWordsA, bagOfWordsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adaptive-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "banned-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([numOfWordsA, numOfWordsA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "front-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "auburn-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfA = computeTFIDF(tfA, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "private-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([tfidfA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "legendary-updating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swing</th>\n",
       "      <th>toss</th>\n",
       "      <th>world</th>\n",
       "      <th>engage</th>\n",
       "      <th>ledge</th>\n",
       "      <th>this</th>\n",
       "      <th>like</th>\n",
       "      <th>dart</th>\n",
       "      <th>flaws</th>\n",
       "      <th>finest</th>\n",
       "      <th>...</th>\n",
       "      <th>fending</th>\n",
       "      <th>trained</th>\n",
       "      <th>hour</th>\n",
       "      <th>any</th>\n",
       "      <th>of</th>\n",
       "      <th>creed</th>\n",
       "      <th>me</th>\n",
       "      <th>eerie</th>\n",
       "      <th>auditore</th>\n",
       "      <th>blade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   swing  toss  world  engage  ledge  this  like  dart  flaws  finest  ...  \\\n",
       "0    0.0   0.0    0.0     0.0    0.0   0.0   0.0   0.0    0.0     0.0  ...   \n",
       "\n",
       "   fending  trained  hour  any   of  creed   me  eerie  auditore  blade  \n",
       "0      0.0      0.0   0.0  0.0  0.0    0.0  0.0    0.0       0.0    0.0  \n",
       "\n",
       "[1 rows x 394 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "parliamentary-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([documentA])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "toxic-sapphire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20</th>\n",
       "      <th>2d</th>\n",
       "      <th>above</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accustomed</th>\n",
       "      <th>achieve</th>\n",
       "      <th>across</th>\n",
       "      <th>add</th>\n",
       "      <th>adventure</th>\n",
       "      <th>affair</th>\n",
       "      <th>...</th>\n",
       "      <th>while</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>xiao</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.056022</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.420166</td>\n",
       "      <td>0.098039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         20        2d     above  absolutely  accustomed   achieve    across  \\\n",
       "0  0.014006  0.014006  0.014006    0.014006    0.014006  0.014006  0.014006   \n",
       "\n",
       "        add  adventure    affair  ...     while      will      with      work  \\\n",
       "0  0.014006   0.014006  0.014006  ...  0.014006  0.056022  0.042017  0.014006   \n",
       "\n",
       "      world     would      xiao       yet       you      your  \n",
       "0  0.014006  0.014006  0.028011  0.028011  0.420166  0.098039  \n",
       "\n",
       "[1 rows x 387 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "three-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Minimum'] = df.loc[:, :].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "noticed-print",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20</th>\n",
       "      <th>2d</th>\n",
       "      <th>above</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accustomed</th>\n",
       "      <th>achieve</th>\n",
       "      <th>across</th>\n",
       "      <th>add</th>\n",
       "      <th>adventure</th>\n",
       "      <th>affair</th>\n",
       "      <th>...</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>xiao</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>Minimum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056022</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.420166</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.014006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         20        2d     above  absolutely  accustomed   achieve    across  \\\n",
       "0  0.014006  0.014006  0.014006    0.014006    0.014006  0.014006  0.014006   \n",
       "\n",
       "        add  adventure    affair  ...      will      with      work     world  \\\n",
       "0  0.014006   0.014006  0.014006  ...  0.056022  0.042017  0.014006  0.014006   \n",
       "\n",
       "      would      xiao       yet       you      your   Minimum  \n",
       "0  0.014006  0.028011  0.028011  0.420166  0.098039  0.014006  \n",
       "\n",
       "[1 rows x 388 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-native",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
