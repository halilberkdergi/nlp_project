{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "novel-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pysummarization.nlpbase.auto_abstractor import AutoAbstractor\n",
    "from pysummarization.tokenizabledoc.simple_tokenizer import SimpleTokenizer\n",
    "from pysummarization.abstractabledoc.top_n_rank_abstractor import TopNRankAbstractor\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "administrative-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(subtitle_file,excel_name,sheet_name):\n",
    "    \n",
    "    #read input file\n",
    "    file = open(subtitle_file)\n",
    "    SENTENCES_COUNT =0         \n",
    "    data = file.read()\n",
    "\n",
    "    CoList = data.split('\\n')\n",
    "\n",
    "    for i in CoList:\n",
    "        if i:        \n",
    "            SENTENCES_COUNT += 1\n",
    "\n",
    "    data = data.replace('\\n', ' . ')\n",
    "    #close the input file\n",
    "    file.close()\n",
    "\n",
    "    ############\n",
    "    #open the input file in write mode\n",
    "    fin = open(subtitle_file, \"wt\")\n",
    "    #overrite the input file with the resulting data\n",
    "    fin.write(data)\n",
    "    #close the file\n",
    "    fin.close()\n",
    "\n",
    "    ###### read again####\n",
    "    document = open(subtitle_file).read()\n",
    "\n",
    "    ####PANDAS####\n",
    "    df = pd.read_excel(excel_name,header=0,sheet_name=sheet_name,index_col=0)\n",
    "    df.index.name = None\n",
    "    df =df.fillna(0)\n",
    "    df= df.astype(int)\n",
    "    \n",
    "\n",
    "    #####PYSUMMM#####\n",
    "    \n",
    "    auto_abstractor = AutoAbstractor() # Object of automatic summarization.\n",
    "    auto_abstractor.tokenizable_doc = SimpleTokenizer() # Set tokenizer.\n",
    "    auto_abstractor.delimiter_list = [\".\"] # Set delimiter for making a list of sentence.\n",
    "    abstractable_doc = TopNRankAbstractor()# Object of abstracting and filtering document.\n",
    "    \n",
    "    for n in range(1,SENTENCES_COUNT+1):\n",
    "        abstractable_doc.set_top_n(n) # set n = 120 value\n",
    "        result_dict = auto_abstractor.summarize(document, abstractable_doc) # Summarize document.\n",
    "        #print(n )\n",
    "\n",
    "        for i in range(n):\n",
    "            a=result_dict[\"scoring_data\"][i][0]+1\n",
    "            #print('a ='+str(a))\n",
    "            if df['pysum'][a]==0:\n",
    "                df['pysum'][a] = n\n",
    "\n",
    "    #####SUMY#########\n",
    "    LANGUAGE = \"english\"\n",
    "    parser = PlaintextParser.from_file(subtitle_file, Tokenizer(LANGUAGE))\n",
    "    summarizer_lex = LexRankSummarizer()\n",
    "\n",
    "    summarizer_luhn = LuhnSummarizer()\n",
    "\n",
    "    summarizer_lsa = LsaSummarizer()\n",
    "\n",
    "    summarizer_textrank = TextRankSummarizer()\n",
    "\n",
    "    for n in range(1,SENTENCES_COUNT):\n",
    "        summary_lex = summarizer_lex(parser.document,n)\n",
    "        summary_luhn = summarizer_luhn(parser.document,n)\n",
    "        summary_lsa = summarizer_lsa(parser.document,n)\n",
    "        summary_textrank = summarizer_textrank(parser.document,n)\n",
    "        for sentence in summary_lex:        \n",
    "            a=parser.document.sentences.index(sentence)+1\n",
    "            #print('a ='+str(a))\n",
    "            if df['lexrank'][a]==0:\n",
    "                df['lexrank'][a] = n\n",
    "        for sentence in summary_luhn:        \n",
    "            a=parser.document.sentences.index(sentence)+1\n",
    "            #print('a ='+str(a))\n",
    "            if df['luhn'][a]==0:\n",
    "                df['luhn'][a] = n\n",
    "        for sentence in summary_lsa:        \n",
    "            a=parser.document.sentences.index(sentence)+1\n",
    "            #print('a ='+str(a))\n",
    "            if df['lsa'][a]==0:\n",
    "                df['lsa'][a] = n\n",
    "        for sentence in summary_textrank:        \n",
    "            a=parser.document.sentences.index(sentence)+1\n",
    "            #print('a ='+str(a))\n",
    "            if df['textrank'][a]==0:\n",
    "                df['textrank'][a] = n\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surface-puzzle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pysum</th>\n",
       "      <th>lexrank</th>\n",
       "      <th>luhn</th>\n",
       "      <th>lsa</th>\n",
       "      <th>textrank</th>\n",
       "      <th>x1.</th>\n",
       "      <th>x1.3</th>\n",
       "      <th>x1.6</th>\n",
       "      <th>x1.9</th>\n",
       "      <th>x2.2</th>\n",
       "      <th>x2.5</th>\n",
       "      <th>nadir_kelime</th>\n",
       "      <th>konu_ile_alakalı</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>63</td>\n",
       "      <td>109</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>102</td>\n",
       "      <td>24</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>83</td>\n",
       "      <td>27</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>97</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>49</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>66</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>106</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pysum  lexrank  luhn  lsa  textrank  x1.  x1.3  x1.6  x1.9  x2.2  x2.5  \\\n",
       "1        8       78    63  109        88    1     1     1     1     1     1   \n",
       "2       11       64   102   24        83    1     1     1     1     1     1   \n",
       "3       10       71    83   27       106    1     1     1     1     1     0   \n",
       "4        7      110     7   18        12    1     1     1     1     1     1   \n",
       "5        6        2     3   17         4    1     1     1     1     1     0   \n",
       "..     ...      ...   ...  ...       ...  ...   ...   ...   ...   ...   ...   \n",
       "116     99       84    97  115         0    1     1     1     1     1     1   \n",
       "117     49       25    21   20        43    1     1     1     1     1     1   \n",
       "118     39       31    32   16        16    1     1     1     1     1     0   \n",
       "119     24       38    33    1         1    1     1     1     1     1     0   \n",
       "120     66       80    73  106        66    0     0     0     0     0     0   \n",
       "\n",
       "     nadir_kelime  konu_ile_alakalı  \n",
       "1               0                 0  \n",
       "2               0                 0  \n",
       "3               0                 0  \n",
       "4               0                 0  \n",
       "5               0                 0  \n",
       "..            ...               ...  \n",
       "116             0                 0  \n",
       "117             0                 0  \n",
       "118             0                 0  \n",
       "119             0                 0  \n",
       "120             0                 0  \n",
       "\n",
       "[120 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank(subtitle_file='Sub_1.txt',excel_name='data.xlsx',sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "emerging-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "right-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentA = open('Sub_1.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "removed-asthma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'was',\n",
       " 'exactly',\n",
       " 'where',\n",
       " 'i',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'be',\n",
       " 'close',\n",
       " '.',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'kill',\n",
       " 'assassin',\n",
       " 'chou',\n",
       " 'john',\n",
       " 'was',\n",
       " '.',\n",
       " 'trained',\n",
       " 'by',\n",
       " 'none',\n",
       " 'other',\n",
       " 'than',\n",
       " 'ezio',\n",
       " 'auditore',\n",
       " '.',\n",
       " 'and',\n",
       " 'she',\n",
       " 'really',\n",
       " 'wants',\n",
       " 'a',\n",
       " 'box',\n",
       " 'the',\n",
       " 'artifact',\n",
       " '.',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " 'is',\n",
       " 'irrelevant',\n",
       " \"it's\",\n",
       " 'just',\n",
       " 'a',\n",
       " '.',\n",
       " 'macguffin',\n",
       " 'that',\n",
       " 'sends',\n",
       " 'her',\n",
       " 'off',\n",
       " 'on',\n",
       " 'a',\n",
       " '2-d',\n",
       " '.',\n",
       " 'stealth',\n",
       " 'adventure',\n",
       " 'called',\n",
       " \"assassin's\",\n",
       " '.',\n",
       " 'creed',\n",
       " 'chronicles',\n",
       " 'china',\n",
       " 'that',\n",
       " 'looks',\n",
       " '.',\n",
       " 'absolutely',\n",
       " 'stunning',\n",
       " 'but',\n",
       " 'ultimately',\n",
       " 'comes',\n",
       " '.',\n",
       " 'off',\n",
       " 'as',\n",
       " 'a',\n",
       " 'mildly',\n",
       " 'enjoyable',\n",
       " 'mark',\n",
       " 'of',\n",
       " 'the',\n",
       " '.',\n",
       " 'ninja',\n",
       " 'wannabe',\n",
       " 'if',\n",
       " 'a',\n",
       " 'game',\n",
       " 'must',\n",
       " 'rest',\n",
       " 'on',\n",
       " '.',\n",
       " 'being',\n",
       " 'pretty',\n",
       " 'then',\n",
       " 'at',\n",
       " 'least',\n",
       " 'chronicles',\n",
       " '.',\n",
       " 'makes',\n",
       " 'the',\n",
       " 'most',\n",
       " 'of',\n",
       " 'it',\n",
       " 'gorgeous',\n",
       " 'moon',\n",
       " 'rises',\n",
       " '.',\n",
       " 'and',\n",
       " 'lush',\n",
       " 'cherry',\n",
       " 'blossoms',\n",
       " 'have',\n",
       " 'the',\n",
       " '.',\n",
       " 'natural',\n",
       " 'smudges',\n",
       " 'and',\n",
       " 'brushstrokes',\n",
       " 'you',\n",
       " '.',\n",
       " 'would',\n",
       " 'expect',\n",
       " 'to',\n",
       " 'see',\n",
       " 'from',\n",
       " 'the',\n",
       " 'chinese',\n",
       " '.',\n",
       " 'masters',\n",
       " 'each',\n",
       " 'scene',\n",
       " 'comes',\n",
       " 'to',\n",
       " 'life',\n",
       " 'with',\n",
       " 'an',\n",
       " '.',\n",
       " 'inviting',\n",
       " 'softness',\n",
       " 'which',\n",
       " 'makes',\n",
       " 'it',\n",
       " '.',\n",
       " 'disappointing',\n",
       " 'that',\n",
       " 'the',\n",
       " 'story',\n",
       " \"doesn't\",\n",
       " '.',\n",
       " 'build',\n",
       " 'this',\n",
       " 'world',\n",
       " 'in',\n",
       " 'any',\n",
       " 'meaningful',\n",
       " 'way',\n",
       " '.',\n",
       " 'as',\n",
       " 'xiao',\n",
       " 'jun',\n",
       " 'you',\n",
       " 'move',\n",
       " 'through',\n",
       " 'these',\n",
       " '.',\n",
       " 'spaces',\n",
       " 'sneaking',\n",
       " 'past',\n",
       " 'patrolling',\n",
       " 'guards',\n",
       " '.',\n",
       " 'and',\n",
       " 'avoiding',\n",
       " 'their',\n",
       " 'vision',\n",
       " 'cones',\n",
       " 'they',\n",
       " '.',\n",
       " \"can't\",\n",
       " 'see',\n",
       " 'more',\n",
       " 'than',\n",
       " '20',\n",
       " 'feet',\n",
       " 'in',\n",
       " 'front',\n",
       " 'of',\n",
       " '.',\n",
       " 'their',\n",
       " 'own',\n",
       " 'faces',\n",
       " 'and',\n",
       " 'will',\n",
       " 'not',\n",
       " 'notice',\n",
       " 'you',\n",
       " '.',\n",
       " 'at',\n",
       " 'all',\n",
       " 'when',\n",
       " 'they',\n",
       " 'engage',\n",
       " 'in',\n",
       " 'conversation',\n",
       " '.',\n",
       " 'with',\n",
       " 'each',\n",
       " 'other',\n",
       " '.',\n",
       " 'avoidance',\n",
       " 'means',\n",
       " 'slipping',\n",
       " 'behind',\n",
       " 'a',\n",
       " 'pillar',\n",
       " '.',\n",
       " 'hanging',\n",
       " 'from',\n",
       " 'a',\n",
       " 'front-facing',\n",
       " 'ledge',\n",
       " '.',\n",
       " 'crawling',\n",
       " 'along',\n",
       " 'a',\n",
       " 'ceiling',\n",
       " 'or',\n",
       " 'tumbling',\n",
       " '.',\n",
       " 'into',\n",
       " 'a',\n",
       " 'pile',\n",
       " 'of',\n",
       " 'hay',\n",
       " 'sometimes',\n",
       " 'you',\n",
       " 'toss',\n",
       " '.',\n",
       " 'your',\n",
       " 'rope',\n",
       " 'dart',\n",
       " 'towards',\n",
       " 'an',\n",
       " 'overhang',\n",
       " 'and',\n",
       " '.',\n",
       " 'swing',\n",
       " 'towards',\n",
       " 'or',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'camera',\n",
       " '.',\n",
       " 'and',\n",
       " 'into',\n",
       " 'a',\n",
       " 'different',\n",
       " 'layer',\n",
       " 'chronicles',\n",
       " '.',\n",
       " 'makes',\n",
       " 'good',\n",
       " 'use',\n",
       " 'of',\n",
       " 'these',\n",
       " 'layers',\n",
       " 'giving',\n",
       " '.',\n",
       " 'its',\n",
       " 'best',\n",
       " 'levels',\n",
       " 'a',\n",
       " 'terrific',\n",
       " 'sense',\n",
       " 'of',\n",
       " '.',\n",
       " 'depth',\n",
       " 'you',\n",
       " 'spend',\n",
       " 'more',\n",
       " 'time',\n",
       " 'however',\n",
       " '.',\n",
       " 'navigating',\n",
       " 'past',\n",
       " 'the',\n",
       " 'guards',\n",
       " 'that',\n",
       " 'bar',\n",
       " 'your',\n",
       " '.',\n",
       " 'way',\n",
       " 'by',\n",
       " 'sneaking',\n",
       " 'around',\n",
       " 'them',\n",
       " '.',\n",
       " 'assassinating',\n",
       " 'them',\n",
       " 'or',\n",
       " 'by',\n",
       " 'directly',\n",
       " '.',\n",
       " 'confronting',\n",
       " 'them',\n",
       " '.',\n",
       " 'it',\n",
       " 'is',\n",
       " 'in',\n",
       " 'silent',\n",
       " 'assassination',\n",
       " 'that',\n",
       " '.',\n",
       " 'chronicle',\n",
       " 'stays',\n",
       " 'truest',\n",
       " 'to',\n",
       " 'the',\n",
       " 'series',\n",
       " '.',\n",
       " 'when',\n",
       " 'you',\n",
       " 'plunge',\n",
       " 'your',\n",
       " 'hidden',\n",
       " 'dagger',\n",
       " 'into',\n",
       " '.',\n",
       " 'an',\n",
       " 'enemy',\n",
       " 'from',\n",
       " 'behind',\n",
       " 'you',\n",
       " 'hear',\n",
       " 'an',\n",
       " 'eerie',\n",
       " '.',\n",
       " 'crunch',\n",
       " 'and',\n",
       " 'blood',\n",
       " 'seeps',\n",
       " 'across',\n",
       " 'the',\n",
       " 'corpse',\n",
       " '.',\n",
       " 'and',\n",
       " 'dissipates',\n",
       " 'performing',\n",
       " 'an',\n",
       " '.',\n",
       " 'assassination',\n",
       " 'while',\n",
       " 'hanging',\n",
       " 'from',\n",
       " 'above',\n",
       " '.',\n",
       " 'is',\n",
       " 'even',\n",
       " 'more',\n",
       " 'enjoyable',\n",
       " 'thanks',\n",
       " 'to',\n",
       " 'the',\n",
       " 'way',\n",
       " '.',\n",
       " 'xiao',\n",
       " 'jun',\n",
       " 'points',\n",
       " 'her',\n",
       " 'blade',\n",
       " 'downward',\n",
       " 'as',\n",
       " '.',\n",
       " 'she',\n",
       " 'falls',\n",
       " 'later',\n",
       " 'on',\n",
       " 'you',\n",
       " 'can',\n",
       " 'sprint',\n",
       " '.',\n",
       " 'forward',\n",
       " 'and',\n",
       " 'slide',\n",
       " 'into',\n",
       " 'unaware',\n",
       " 'guards',\n",
       " '.',\n",
       " 'which',\n",
       " 'makes',\n",
       " 'for',\n",
       " 'a',\n",
       " 'rewarding',\n",
       " 'combination',\n",
       " '.',\n",
       " 'of',\n",
       " 'momentum',\n",
       " 'and',\n",
       " 'violence',\n",
       " 'the',\n",
       " 'game',\n",
       " 'awards',\n",
       " '.',\n",
       " 'you',\n",
       " 'the',\n",
       " 'most',\n",
       " 'points',\n",
       " 'for',\n",
       " 'staying',\n",
       " 'hidden',\n",
       " '.',\n",
       " 'yet',\n",
       " \"it's\",\n",
       " 'in',\n",
       " 'the',\n",
       " 'pure',\n",
       " 'stealth',\n",
       " 'that',\n",
       " '.',\n",
       " 'chronicles',\n",
       " 'flaws',\n",
       " 'most',\n",
       " 'often',\n",
       " 'surface',\n",
       " 'in',\n",
       " '.',\n",
       " 'any',\n",
       " 'stealth',\n",
       " 'game',\n",
       " 'there',\n",
       " 'is',\n",
       " 'intrinsic',\n",
       " '.',\n",
       " 'reward',\n",
       " 'and',\n",
       " 'staying',\n",
       " 'out',\n",
       " 'of',\n",
       " 'sight',\n",
       " 'yet',\n",
       " 'over',\n",
       " '.',\n",
       " 'the',\n",
       " \"game's\",\n",
       " 'four',\n",
       " 'hour',\n",
       " 'or',\n",
       " 'so',\n",
       " 'running',\n",
       " 'time',\n",
       " '.',\n",
       " 'the',\n",
       " 'challenge',\n",
       " 'rarely',\n",
       " 'grows',\n",
       " 'you',\n",
       " 'earn',\n",
       " '.',\n",
       " 'upgrades',\n",
       " 'to',\n",
       " 'your',\n",
       " 'stealth',\n",
       " 'repertoire',\n",
       " 'as',\n",
       " '.',\n",
       " 'you',\n",
       " 'progress',\n",
       " 'but',\n",
       " \"there's\",\n",
       " 'no',\n",
       " 'sense',\n",
       " 'of',\n",
       " '.',\n",
       " 'rising',\n",
       " 'tension',\n",
       " 'the',\n",
       " 'stealth',\n",
       " 'puzzles',\n",
       " 'never',\n",
       " '.',\n",
       " 'become',\n",
       " 'all',\n",
       " 'that',\n",
       " 'challenging',\n",
       " 'and',\n",
       " 'a',\n",
       " 'few',\n",
       " '.',\n",
       " 'ideas',\n",
       " 'like',\n",
       " 'birds',\n",
       " 'and',\n",
       " 'dogs',\n",
       " 'that',\n",
       " 'give',\n",
       " 'you',\n",
       " '.',\n",
       " 'away',\n",
       " 'are',\n",
       " 'too',\n",
       " 'rare',\n",
       " 'to',\n",
       " 'add',\n",
       " 'much',\n",
       " 'anxiety',\n",
       " 'to',\n",
       " '.',\n",
       " 'sneaking',\n",
       " '.',\n",
       " 'in',\n",
       " 'time',\n",
       " 'you',\n",
       " 'discover',\n",
       " 'ways',\n",
       " 'to',\n",
       " 'exploit',\n",
       " 'the',\n",
       " '.',\n",
       " \"ai's\",\n",
       " 'limitations',\n",
       " 'rushing',\n",
       " 'out',\n",
       " 'of',\n",
       " 'guards',\n",
       " '.',\n",
       " 'view',\n",
       " 'if',\n",
       " 'you',\n",
       " 'alert',\n",
       " 'all',\n",
       " 'of',\n",
       " 'them',\n",
       " 'and',\n",
       " '.',\n",
       " 'waiting',\n",
       " 'to',\n",
       " 'return',\n",
       " 'until',\n",
       " 'they',\n",
       " 'resume',\n",
       " '.',\n",
       " 'patrolling',\n",
       " 'just',\n",
       " 'a',\n",
       " 'few',\n",
       " 'seconds',\n",
       " 'later',\n",
       " 'you',\n",
       " '.',\n",
       " 'have',\n",
       " 'gadgets',\n",
       " 'like',\n",
       " 'throwing',\n",
       " 'knives',\n",
       " 'at',\n",
       " '.',\n",
       " 'your',\n",
       " 'disposal',\n",
       " 'but',\n",
       " 'you',\n",
       " 'rarely',\n",
       " 'need',\n",
       " 'to',\n",
       " 'use',\n",
       " '.',\n",
       " 'them',\n",
       " 'in',\n",
       " 'creative',\n",
       " 'ways',\n",
       " 'since',\n",
       " 'the',\n",
       " 'same',\n",
       " '.',\n",
       " 'basic',\n",
       " 'strategies',\n",
       " 'usually',\n",
       " 'work',\n",
       " 'in',\n",
       " 'any',\n",
       " '.',\n",
       " 'given',\n",
       " 'situation',\n",
       " 'and',\n",
       " 'occasionally',\n",
       " 'the',\n",
       " '.',\n",
       " 'game',\n",
       " \"doesn't\",\n",
       " 'know',\n",
       " 'how',\n",
       " 'to',\n",
       " 'respond',\n",
       " 'to',\n",
       " 'your',\n",
       " '.',\n",
       " 'reactions',\n",
       " 'and',\n",
       " 'glitches',\n",
       " 'out',\n",
       " 'guards',\n",
       " 'might',\n",
       " '.',\n",
       " 'freeze',\n",
       " 'in',\n",
       " 'place',\n",
       " 'until',\n",
       " 'you',\n",
       " 'move',\n",
       " 'out',\n",
       " 'of',\n",
       " '.',\n",
       " 'hiding',\n",
       " 'for',\n",
       " 'example',\n",
       " 'then',\n",
       " \"there's\",\n",
       " 'combat',\n",
       " '.',\n",
       " 'combats',\n",
       " 'never',\n",
       " 'been',\n",
       " \"assassin's\",\n",
       " 'creed',\n",
       " '.',\n",
       " 'strong',\n",
       " 'suit',\n",
       " 'but',\n",
       " 'swordplay',\n",
       " 'has',\n",
       " 'always',\n",
       " 'had',\n",
       " '.',\n",
       " 'an',\n",
       " 'easy-to-understand',\n",
       " 'rhythm',\n",
       " 'and',\n",
       " '.',\n",
       " 'chronicles',\n",
       " 'fending',\n",
       " 'off',\n",
       " 'guards',\n",
       " 'is',\n",
       " 'hardly',\n",
       " '.',\n",
       " 'fun',\n",
       " \"it's\",\n",
       " 'possible',\n",
       " 'to',\n",
       " 'escape',\n",
       " 'with',\n",
       " 'your',\n",
       " '.',\n",
       " 'life',\n",
       " 'if',\n",
       " \"you're\",\n",
       " 'really',\n",
       " 'careful',\n",
       " 'but',\n",
       " 'the',\n",
       " '.',\n",
       " 'entire',\n",
       " 'affair',\n",
       " 'is',\n",
       " 'clumsy',\n",
       " \"there's\",\n",
       " 'no',\n",
       " '.',\n",
       " 'cadence',\n",
       " 'to',\n",
       " 'enemy',\n",
       " 'behavior',\n",
       " 'and',\n",
       " 'the',\n",
       " '.',\n",
       " 'controls',\n",
       " 'are',\n",
       " 'fiddly',\n",
       " 'direct',\n",
       " 'confrontation',\n",
       " '.',\n",
       " 'is',\n",
       " 'best',\n",
       " 'avoided',\n",
       " 'as',\n",
       " 'you',\n",
       " 'can',\n",
       " 'imagine',\n",
       " 'in',\n",
       " 'a',\n",
       " '.',\n",
       " 'stealth',\n",
       " 'game',\n",
       " 'ironically',\n",
       " 'this',\n",
       " 'stealth',\n",
       " '.',\n",
       " 'games',\n",
       " 'finest',\n",
       " 'moments',\n",
       " 'arrive',\n",
       " 'when',\n",
       " 'you',\n",
       " '.',\n",
       " 'escape',\n",
       " 'looming',\n",
       " 'danger',\n",
       " 'such',\n",
       " 'as',\n",
       " 'a',\n",
       " 'blazing',\n",
       " '.',\n",
       " 'fire',\n",
       " 'these',\n",
       " 'sequences',\n",
       " 'of',\n",
       " 'the',\n",
       " 'closest',\n",
       " '.',\n",
       " 'chronicles',\n",
       " 'comes',\n",
       " 'to',\n",
       " 'delivering',\n",
       " 'the',\n",
       " '.',\n",
       " 'series',\n",
       " 'signature',\n",
       " 'free',\n",
       " 'running',\n",
       " 'you',\n",
       " 'vault',\n",
       " '.',\n",
       " 'over',\n",
       " 'obstacles',\n",
       " 'and',\n",
       " 'slide',\n",
       " 'into',\n",
       " '.',\n",
       " 'shell-shocked',\n",
       " 'guards',\n",
       " 'cutting',\n",
       " 'them',\n",
       " 'down',\n",
       " '.',\n",
       " 'as',\n",
       " 'you',\n",
       " 'sprint',\n",
       " 'ahead',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'lively',\n",
       " '.',\n",
       " 'diversion',\n",
       " 'in',\n",
       " 'a',\n",
       " 'game',\n",
       " 'that',\n",
       " 'is',\n",
       " 'otherwise',\n",
       " '.',\n",
       " 'mostly',\n",
       " 'devoid',\n",
       " 'of',\n",
       " 'momentum',\n",
       " 'you',\n",
       " 'know',\n",
       " 'the',\n",
       " '.',\n",
       " 'end',\n",
       " 'is',\n",
       " 'coming',\n",
       " 'but',\n",
       " 'there',\n",
       " 'was',\n",
       " 'no',\n",
       " 'more',\n",
       " '.',\n",
       " 'excitement',\n",
       " 'in',\n",
       " 'that',\n",
       " 'finale',\n",
       " 'than',\n",
       " 'there',\n",
       " 'was',\n",
       " '.',\n",
       " 'in',\n",
       " 'the',\n",
       " 'opening',\n",
       " 'minutes',\n",
       " 'chronicles',\n",
       " '.',\n",
       " 'passive',\n",
       " 'pacing',\n",
       " 'is',\n",
       " 'a',\n",
       " 'shame',\n",
       " 'because',\n",
       " 'the',\n",
       " '.',\n",
       " 'pieces',\n",
       " 'are',\n",
       " 'mostly',\n",
       " 'strong',\n",
       " 'but',\n",
       " 'once',\n",
       " 'you',\n",
       " '.',\n",
       " 'get',\n",
       " 'past',\n",
       " 'the',\n",
       " \"game's\",\n",
       " 'looks',\n",
       " 'and',\n",
       " 'get',\n",
       " '.',\n",
       " 'accustomed',\n",
       " 'to',\n",
       " 'its',\n",
       " '2d',\n",
       " 'stealth',\n",
       " '.',\n",
       " \"there's\",\n",
       " 'too',\n",
       " 'little',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'you',\n",
       " 'moving',\n",
       " '.',\n",
       " 'forward',\n",
       " \"assassin's\",\n",
       " 'creed',\n",
       " 'chronicles',\n",
       " '.',\n",
       " 'china',\n",
       " 'is',\n",
       " 'as',\n",
       " 'lovely',\n",
       " 'as',\n",
       " 'a',\n",
       " 'postcard',\n",
       " 'but',\n",
       " '.',\n",
       " 'when',\n",
       " \"you're\",\n",
       " 'a',\n",
       " 'tourist',\n",
       " 'you',\n",
       " 'need',\n",
       " 'more',\n",
       " 'than',\n",
       " '.',\n",
       " 'just',\n",
       " 'pretty',\n",
       " 'sights',\n",
       " 'thinking',\n",
       " 'that',\n",
       " 'killing',\n",
       " '.',\n",
       " 'me',\n",
       " 'will',\n",
       " 'achieve',\n",
       " '.',\n",
       " \"eddie's\",\n",
       " 'killing',\n",
       " 'just',\n",
       " 'one',\n",
       " 'of',\n",
       " 'you',\n",
       " 'will',\n",
       " 'not',\n",
       " '.',\n",
       " 'give',\n",
       " 'me',\n",
       " 'defendants',\n",
       " 'i',\n",
       " 'seek',\n",
       " 'you',\n",
       " 'are',\n",
       " 'the',\n",
       " '.',\n",
       " 'first',\n",
       " 'of',\n",
       " 'the',\n",
       " 'tigers',\n",
       " 'to',\n",
       " 'fall',\n",
       " 'but',\n",
       " 'you',\n",
       " 'will',\n",
       " '.',\n",
       " 'not',\n",
       " 'be',\n",
       " 'the',\n",
       " 'last']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagOfWordsA = documentA.split(' ')\n",
    "bagOfWordsA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "practical-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = set(bagOfWordsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "committed-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsA:\n",
    "    numOfWordsA[word] += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "located-marathon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords. words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wicked-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bizarre-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfA = computeTF(numOfWordsA, bagOfWordsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adaptive-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "banned-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([numOfWordsA, numOfWordsA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "front-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "auburn-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfA = computeTFIDF(tfA, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "private-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([tfidfA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "legendary-updating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swing</th>\n",
       "      <th>toss</th>\n",
       "      <th>world</th>\n",
       "      <th>engage</th>\n",
       "      <th>ledge</th>\n",
       "      <th>this</th>\n",
       "      <th>like</th>\n",
       "      <th>dart</th>\n",
       "      <th>flaws</th>\n",
       "      <th>finest</th>\n",
       "      <th>...</th>\n",
       "      <th>fending</th>\n",
       "      <th>trained</th>\n",
       "      <th>hour</th>\n",
       "      <th>any</th>\n",
       "      <th>of</th>\n",
       "      <th>creed</th>\n",
       "      <th>me</th>\n",
       "      <th>eerie</th>\n",
       "      <th>auditore</th>\n",
       "      <th>blade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   swing  toss  world  engage  ledge  this  like  dart  flaws  finest  ...  \\\n",
       "0    0.0   0.0    0.0     0.0    0.0   0.0   0.0   0.0    0.0     0.0  ...   \n",
       "\n",
       "   fending  trained  hour  any   of  creed   me  eerie  auditore  blade  \n",
       "0      0.0      0.0   0.0  0.0  0.0    0.0  0.0    0.0       0.0    0.0  \n",
       "\n",
       "[1 rows x 394 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "parliamentary-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([documentA])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "toxic-sapphire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20</th>\n",
       "      <th>2d</th>\n",
       "      <th>above</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accustomed</th>\n",
       "      <th>achieve</th>\n",
       "      <th>across</th>\n",
       "      <th>add</th>\n",
       "      <th>adventure</th>\n",
       "      <th>affair</th>\n",
       "      <th>...</th>\n",
       "      <th>while</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>xiao</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.056022</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.420166</td>\n",
       "      <td>0.098039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         20        2d     above  absolutely  accustomed   achieve    across  \\\n",
       "0  0.014006  0.014006  0.014006    0.014006    0.014006  0.014006  0.014006   \n",
       "\n",
       "        add  adventure    affair  ...     while      will      with      work  \\\n",
       "0  0.014006   0.014006  0.014006  ...  0.014006  0.056022  0.042017  0.014006   \n",
       "\n",
       "      world     would      xiao       yet       you      your  \n",
       "0  0.014006  0.014006  0.028011  0.028011  0.420166  0.098039  \n",
       "\n",
       "[1 rows x 387 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "three-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Minimum'] = df.loc[:, :].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "noticed-print",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20</th>\n",
       "      <th>2d</th>\n",
       "      <th>above</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accustomed</th>\n",
       "      <th>achieve</th>\n",
       "      <th>across</th>\n",
       "      <th>add</th>\n",
       "      <th>adventure</th>\n",
       "      <th>affair</th>\n",
       "      <th>...</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>xiao</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>Minimum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056022</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.420166</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.014006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         20        2d     above  absolutely  accustomed   achieve    across  \\\n",
       "0  0.014006  0.014006  0.014006    0.014006    0.014006  0.014006  0.014006   \n",
       "\n",
       "        add  adventure    affair  ...      will      with      work     world  \\\n",
       "0  0.014006   0.014006  0.014006  ...  0.056022  0.042017  0.014006  0.014006   \n",
       "\n",
       "      would      xiao       yet       you      your   Minimum  \n",
       "0  0.014006  0.028011  0.028011  0.420166  0.098039  0.014006  \n",
       "\n",
       "[1 rows x 388 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-native",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
